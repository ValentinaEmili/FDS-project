{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbIe096NTbkV",
        "outputId": "bd0f995b-7f5c-455b-ff33-ec62043207c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/Progetto/train.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gdown\n",
        "from sklearn.metrics import  confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder,  StandardScaler, MinMaxScaler,LabelEncoder\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "\n",
        "\n",
        "url = \"https://drive.google.com/drive/folders/1K28d1ufLIZL6WtQIS4CE4H_EZZAzvTqX?usp=drive_link\"\n",
        "gdown.download_folder(url, quiet=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **With one hot encoding**"
      ],
      "metadata": {
        "id": "HAG1mPvifkC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data preprocessing with OneHot encoding\n",
        "X = pd.read_csv(\"/content/Progetto/train.csv\")\n",
        "def handle_dataset(X):\n",
        "  y = X['Crime_Category']\n",
        "  X = X.drop('Crime_Category', axis=1)\n",
        "\n",
        "  # remove column with 80% null values\n",
        "  X.drop('Cross_Street', axis=1)\n",
        "\n",
        "  # handle missing data\n",
        "  X['Victim_Sex'] = X['Victim_Sex'].replace(['H', 'X'], 'Unknown')\n",
        "  X['Victim_Descent'] = X['Victim_Descent'].fillna('Unknown')\n",
        "  X['Weapon_Description'] = X['Weapon_Description'].fillna('No Weapon')\n",
        "  X['Weapon_Used_Code'] = X['Weapon_Used_Code'].fillna(0) # Weapon_Used_Code is in the range [1,3990], 0 is for missing code\n",
        "  X['Modus_Operandi'] = X['Modus_Operandi'].fillna('Unknown')\n",
        "\n",
        "  # data handling\n",
        "  X['Date_Reported'] = pd.to_datetime(X['Date_Reported'], format='%m/%d/%Y %I:%M:%S %p', errors='coerce')\n",
        "  X['Date_Occurred'] = pd.to_datetime(X['Date_Occurred'], format='%m/%d/%Y %I:%M:%S %p', errors='coerce')\n",
        "  X['Year_Reported'] = X.Date_Reported.dt.year\n",
        "  X['Year_Occurred'] = X.Date_Occurred.dt.year\n",
        "  X['Month_Reported'] = X.Date_Reported.dt.month\n",
        "  X['Month_Occurred'] = X.Date_Occurred.dt.month\n",
        "  X['Day_Reported'] = X.Date_Reported.dt.day\n",
        "  X['Day_Occurred'] = X.Date_Occurred.dt.day\n",
        "  X.drop(['Date_Reported', 'Date_Occurred'], axis=1, inplace=True)\n",
        "\n",
        "  numerical_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "  categorical_columns = X.select_dtypes(include=['object']).columns.tolist()\n",
        "  categorical_columns = [col for col in categorical_columns if col != 'Modus_Operandi']\n",
        "\n",
        "  numerical_pipeline = make_pipeline(\n",
        "      SimpleImputer(strategy='median'),\n",
        "      StandardScaler()\n",
        "  )\n",
        "\n",
        "  categorical_pipeline = make_pipeline(\n",
        "      SimpleImputer(strategy='most_frequent'),\n",
        "      OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "      )\n",
        "\n",
        "  modus_operandi_pipeline = make_pipeline(\n",
        "      SimpleImputer(strategy='most_frequent'),\n",
        "      CountVectorizer(preprocessor=lambda x:x[0])\n",
        "  )\n",
        "\n",
        "  preprocessor = ColumnTransformer(transformers=[\n",
        "      ('num', numerical_pipeline, numerical_columns),\n",
        "      ('cat', categorical_pipeline, categorical_columns),\n",
        "      ('modus_operandi', modus_operandi_pipeline, ['Modus_Operandi'])\n",
        "    ])\n",
        "\n",
        "  #Split data\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "  # full pipeline\n",
        "  pipe = make_pipeline(\n",
        "    preprocessor,\n",
        "   LogisticRegression()\n",
        ")\n",
        "  #Transform data\n",
        "  # X_train = pipe.fit_transform(X_train)\n",
        "  # X_test = pipe.transform(X_test)\n",
        "  label_encoder = LabelEncoder()\n",
        "  y_train= label_encoder.fit_transform(y_train)\n",
        "  y_test=label_encoder.transform(y_test)\n",
        "  return X_train, X_test, y_train, y_test,pipe\n"
      ],
      "metadata": {
        "id": "_iKDEHmFVMZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test,pipe=handle_dataset(X)\n",
        "# Define the parameter grid based on the logisticregression model\n",
        "grid = {\n",
        "    'logisticregression__C': [0.001, 0.01, 0.1, 1, 10],\n",
        "    'logisticregression__penalty': ['l1', 'l2'],\n",
        "    'logisticregression__solver': ['liblinear', 'newton-cg']\n",
        "}\n",
        "#pipe_cv = GridSearchCV(pipeline, grid, cv=5, scoring='accuracy')\n",
        "pipe_cv = GridSearchCV(pipe,grid,cv=2,verbose=1,n_jobs=-1)\n",
        "\n",
        "if pipe_cv is not None:\n",
        "    pipe_cv.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best score: {pipe_cv.best_score_}\")\n",
        "    for hp, val in pipe_cv.best_params_.items():\n",
        "        print(f\"{hp}: {val}\")\n",
        "\n",
        "#pipeline.fit(X_train,y_train)\n",
        "y_pred = pipe_cv.predict(X_test)\n",
        "print(\"Logistic Regression Model:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "mbrOt9FeVT5j"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy: 0.952"
      ],
      "metadata": {
        "id": "IZsW39z1VWRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **With label encoding**"
      ],
      "metadata": {
        "id": "_YXH7X8kgzvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data preprocessing with Label encoding\n",
        "X = pd.read_csv(\"/content/Progetto/train.csv\")\n",
        "def handle_dataset_v2(X):\n",
        "  y = X['Crime_Category']\n",
        "  X = X.drop('Crime_Category', axis=1)\n",
        "\n",
        "  # remove column with 80% null values\n",
        "  X.drop('Cross_Street', axis=1)\n",
        "\n",
        "  # handle missing data\n",
        "  X['Victim_Sex'] = X['Victim_Sex'].replace(['H', 'X'], 'Unknown')\n",
        "  X['Victim_Descent'] = X['Victim_Descent'].fillna('Unknown')\n",
        "  X['Weapon_Description'] = X['Weapon_Description'].fillna('No Weapon')\n",
        "  X['Weapon_Used_Code'] = X['Weapon_Used_Code'].fillna(0) # Weapon_Used_Code is in the range [1,3990], 0 is for missing code\n",
        "  X['Modus_Operandi'] = X['Modus_Operandi'].fillna('Unknown')\n",
        "\n",
        "  # data handling\n",
        "  X['Date_Reported'] = pd.to_datetime(X['Date_Reported'], format='%m/%d/%Y %I:%M:%S %p', errors='coerce')\n",
        "  X['Date_Occurred'] = pd.to_datetime(X['Date_Occurred'], format='%m/%d/%Y %I:%M:%S %p', errors='coerce')\n",
        "  X['Year_Reported'] = X.Date_Reported.dt.year\n",
        "  X['Year_Occurred'] = X.Date_Occurred.dt.year\n",
        "  X['Month_Reported'] = X.Date_Reported.dt.month\n",
        "  X['Month_Occurred'] = X.Date_Occurred.dt.month\n",
        "  X['Day_Reported'] = X.Date_Reported.dt.day\n",
        "  X['Day_Occurred'] = X.Date_Occurred.dt.day\n",
        "  X.drop(['Date_Reported', 'Date_Occurred'], axis=1, inplace=True)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "  numerical_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "  categorical_columns = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "  numerical_pipeline = make_pipeline(\n",
        "      SimpleImputer(strategy='median'),\n",
        "      StandardScaler()\n",
        "  )\n",
        "\n",
        "  def label_encoding_column(df, column):\n",
        "      lab_encoder = LabelEncoder()\n",
        "      df[column] = lab_encoder.fit_transform(df[column])\n",
        "      return df\n",
        "\n",
        "  for col in categorical_columns:\n",
        "    if col == 'Modus_Operandi':\n",
        "      continue\n",
        "    X = label_encoding_column(X, col)\n",
        "\n",
        "  modus_operandi_pipeline = make_pipeline(\n",
        "      SimpleImputer(strategy='most_frequent'),\n",
        "      CountVectorizer(preprocessor=lambda x:x[0])\n",
        "  )\n",
        "\n",
        "  preprocessor = ColumnTransformer(transformers=[\n",
        "      ('num', numerical_pipeline, numerical_columns),\n",
        "      ('modus_operandi', modus_operandi_pipeline, ['Modus_Operandi'])\n",
        "    ])\n",
        "\n",
        "# full pipeline\n",
        "  pipe = make_pipeline(\n",
        "    preprocessor,\n",
        "   LogisticRegression()\n",
        ")\n",
        "  #Transform data\n",
        "  label_encoder = LabelEncoder()\n",
        "  y_train= label_encoder.fit_transform(y_train)\n",
        "  y_test=label_encoder.transform(y_test)\n",
        "  return X_train, X_test, y_train, y_test,pipe"
      ],
      "metadata": {
        "id": "ok9hDmgzVayC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test,pipe=handle_dataset_v2(X)\n",
        "# Define the parameter grid based on the logisticregression model\n",
        "grid = {\n",
        "    'logisticregression__C': [0.001, 0.01, 0.1, 1, 10],\n",
        "    'logisticregression__penalty': ['l1', 'l2'],\n",
        "    'logisticregression__solver': ['liblinear', 'newton-cg']\n",
        "}\n",
        "#pipe_cv = GridSearchCV(pipeline, grid, cv=5, scoring='accuracy')\n",
        "pipe_cv = GridSearchCV(pipe,grid,cv=2,verbose=1,n_jobs=-1)\n",
        "\n",
        "if pipe_cv is not None:\n",
        "    pipe_cv.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best score: {pipe_cv.best_score_}\")\n",
        "    for hp, val in pipe_cv.best_params_.items():\n",
        "        print(f\"{hp}: {val}\")\n",
        "\n",
        "#pipeline.fit(X_train,y_train)\n",
        "y_pred = pipe_cv.predict(X_test)\n",
        "print(\"Logistic Regression Model:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "cRzpI9a1VdBa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy: 0.9455"
      ],
      "metadata": {
        "id": "NKldZIJ8Ve8U"
      }
    }
  ]
}