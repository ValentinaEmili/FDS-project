{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u0T8vFXSHrXL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hB54fEJEHlmg"
      },
      "outputs": [],
      "source": [
        "# data preprocessing with OneHot encoding\n",
        "\n",
        "X = pd.read_csv(\"train.csv\")\n",
        "y = X['Crime_Category']\n",
        "X = X.drop('Crime_Category', axis=1)\n",
        "\n",
        "# remove column with 80% null values\n",
        "X.drop('Cross_Street', axis=1, inplace=True)\n",
        "\n",
        "# handle missing data\n",
        "X['Victim_Sex'] = X['Victim_Sex'].replace(['H', 'X'], 'Unknown')\n",
        "X['Victim_Descent'] = X['Victim_Descent'].fillna('Unknown')\n",
        "X['Weapon_Description'] = X['Weapon_Description'].fillna('No Weapon')\n",
        "X['Weapon_Used_Code'] = X['Weapon_Used_Code'].fillna(0) # Weapon_Used_Code is in the range [1,3990], 0 is for missing code\n",
        "X['Modus_Operandi'] = X['Modus_Operandi'].fillna('Unknown')\n",
        "\n",
        "# data handling\n",
        "X['Date_Reported'] = pd.to_datetime(X['Date_Reported'], format='%m/%d/%Y %I:%M:%S %p', errors='coerce')\n",
        "X['Date_Occurred'] = pd.to_datetime(X['Date_Occurred'], format='%m/%d/%Y %I:%M:%S %p', errors='coerce')\n",
        "X['Year_Reported'] = X.Date_Reported.dt.year\n",
        "X['Year_Occurred'] = X.Date_Occurred.dt.year\n",
        "X['Month_Reported'] = X.Date_Reported.dt.month\n",
        "X['Month_Occurred'] = X.Date_Occurred.dt.month\n",
        "X['Day_Reported'] = X.Date_Reported.dt.day\n",
        "X['Day_Occurred'] = X.Date_Occurred.dt.day\n",
        "X.drop(['Date_Reported', 'Date_Occurred'], axis=1, inplace=True)\n",
        "\n",
        "numerical_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_columns = X.select_dtypes(include=['object']).columns.tolist()\n",
        "categorical_columns = [col for col in categorical_columns if col != 'Modus_Operandi']\n",
        "\n",
        "numerical_pipeline = make_pipeline(\n",
        "    SimpleImputer(strategy='median'),\n",
        "    StandardScaler()\n",
        ")\n",
        "\n",
        "categorical_pipeline = make_pipeline(\n",
        "    SimpleImputer(strategy='most_frequent'),\n",
        "    OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first')\n",
        "    )\n",
        "\n",
        "modus_operandi_pipeline = make_pipeline(\n",
        "    SimpleImputer(strategy='most_frequent'),\n",
        "    CountVectorizer(preprocessor=lambda x:x[0])\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numerical_pipeline, numerical_columns),\n",
        "    ('cat', categorical_pipeline, categorical_columns),\n",
        "    ('modus_operandi', modus_operandi_pipeline, ['Modus_Operandi'])\n",
        "  ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f_OOOgg9bHo"
      },
      "outputs": [],
      "source": [
        "# data preprocessing with Label encoding\n",
        "\n",
        "X = pd.read_csv(\"train.csv\")\n",
        "y = X['Crime_Category']\n",
        "X = X.drop('Crime_Category', axis=1)\n",
        "\n",
        "# remove column with 80% null values\n",
        "X.drop('Cross_Street', axis=1, inplace=True)\n",
        "\n",
        "# handle missing data\n",
        "X['Victim_Sex'] = X['Victim_Sex'].replace(['H', 'X'], 'Unknown')\n",
        "X['Victim_Descent'] = X['Victim_Descent'].fillna('Unknown')\n",
        "X['Weapon_Description'] = X['Weapon_Description'].fillna('No Weapon')\n",
        "X['Weapon_Used_Code'] = X['Weapon_Used_Code'].fillna(0) # Weapon_Used_Code is in the range [1,3990], 0 is for missing code\n",
        "X['Modus_Operandi'] = X['Modus_Operandi'].fillna('Unknown')\n",
        "\n",
        "# data handling\n",
        "X['Date_Reported'] = pd.to_datetime(X['Date_Reported'], format='%m/%d/%Y %I:%M:%S %p', errors='coerce')\n",
        "X['Date_Occurred'] = pd.to_datetime(X['Date_Occurred'], format='%m/%d/%Y %I:%M:%S %p', errors='coerce')\n",
        "X['Year_Reported'] = X.Date_Reported.dt.year\n",
        "X['Year_Occurred'] = X.Date_Occurred.dt.year\n",
        "X['Month_Reported'] = X.Date_Reported.dt.month\n",
        "X['Month_Occurred'] = X.Date_Occurred.dt.month\n",
        "X['Day_Reported'] = X.Date_Reported.dt.day\n",
        "X['Day_Occurred'] = X.Date_Occurred.dt.day\n",
        "X.drop(['Date_Reported', 'Date_Occurred'], axis=1, inplace=True)\n",
        "\n",
        "numerical_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_columns = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "numerical_pipeline = make_pipeline(\n",
        "    SimpleImputer(strategy='median'),\n",
        "    StandardScaler()\n",
        ")\n",
        "\n",
        "def label_encoding_column(df, column):\n",
        "    lab_encoder = LabelEncoder()\n",
        "    df[column] = lab_encoder.fit_transform(df[column])\n",
        "    return df\n",
        "\n",
        "for col in categorical_columns:\n",
        "  if col == 'Modus_Operandi':\n",
        "    continue\n",
        "  X = label_encoding_column(X, col)\n",
        "\n",
        "modus_operandi_pipeline = make_pipeline(\n",
        "    SimpleImputer(strategy='most_frequent'),\n",
        "    CountVectorizer(preprocessor=lambda x:x[0])\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numerical_pipeline, numerical_columns),\n",
        "    ('modus_operandi', modus_operandi_pipeline, ['Modus_Operandi'])\n",
        "  ])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy with OneHot Encoding before hyper parameters tuning: 92.76%\n",
        "\n",
        "Accuracy with Label Encoding before hyper parameters tuning: 95.425%"
      ],
      "metadata": {
        "id": "_hbpwgxvWINP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fTj5TWyAK2J1"
      },
      "outputs": [],
      "source": [
        "# full pipeline\n",
        "pipe = make_pipeline(\n",
        "    preprocessor,\n",
        "    RandomForestClassifier(random_state=42)\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# encode target labels\n",
        "y_encoder = LabelEncoder()\n",
        "y_train_encoded = y_encoder.fit_transform(y_train.values.ravel())\n",
        "y_test_encoded = y_encoder.transform(y_test.values.ravel())\n",
        "\n",
        "# evaluation before tuning\n",
        "#pipe.fit(X_train, y_train_encoded)\n",
        "#y_pred = pipe.predict(X_test)\n",
        "#accuracy = accuracy_score(y_test_encoded, y_pred)\n",
        "#class_report = classification_report(y_test_encoded, y_pred)\n",
        "#print(\"Random Forest Performance before tuning:\")\n",
        "#print(class_report)\n",
        "#print(\"Accuracy before tuning:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlczMWOBH2vi"
      },
      "outputs": [],
      "source": [
        "# hyperparameters visualizations\n",
        "hparams = pipe.get_params()\n",
        "for hp, val in hparams.items():\n",
        "    if type(val) not in [int, float, str]:\n",
        "        continue\n",
        "    print(f\"{hp}: {val}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters tuning for onehot encoding\n",
        "grid = dict(\n",
        "    {\n",
        "        'randomforestclassifier__min_samples_leaf': [1, 2],\n",
        "        'randomforestclassifier__min_samples_split': [2, 3],\n",
        "    }\n",
        ")\n",
        "\n",
        "pipe_cv = GridSearchCV(pipe, grid, cv=3, verbose=1, n_jobs=-1)\n",
        "pipe_cv.fit(X_train, y_train_encoded)\n",
        "print(f\"Best score: {pipe_cv.best_score_}\")\n",
        "for hp, val in pipe_cv.best_params_.items():\n",
        "    print(f\"{hp}: {val}\")\n",
        "\n",
        "# evaluation after tuning\n",
        "y_pred = pipe_cv.predict(X_test)\n",
        "print(classification_report(y_test_encoded, y_pred))\n",
        "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
        "print('final accuracy: ', accuracy)"
      ],
      "metadata": {
        "id": "qhrO4I4CWiwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UQ7IAi8WCjwv"
      },
      "outputs": [],
      "source": [
        "# hyperparameters tuning for label encoding\n",
        "grid = dict(\n",
        "    {\n",
        "        'randomforestclassifier__n_estimators': [100, 200]\n",
        "    }\n",
        ")\n",
        "\n",
        "pipe_cv = GridSearchCV(pipe, grid, cv=3, verbose=1, n_jobs=-1)\n",
        "pipe_cv.fit(X_train, y_train_encoded)\n",
        "print(f\"Best score: {pipe_cv.best_score_}\")\n",
        "for hp, val in pipe_cv.best_params_.items():\n",
        "    print(f\"{hp}: {val}\")\n",
        "\n",
        "# evaluation after tuning\n",
        "y_pred = pipe_cv.predict(X_test)\n",
        "print(classification_report(y_test_encoded, y_pred))\n",
        "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
        "print('final accuracy: ', accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy with OneHot Encoding after hyper parameters tuning: 93.025%\n",
        "\n",
        "Accuracy with Label Encoding after hyper parameters tuning: 95.6%"
      ],
      "metadata": {
        "id": "zkIoFn7wWUbq"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}