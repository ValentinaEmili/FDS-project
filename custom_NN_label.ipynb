{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing with Label encoding\n",
    "X = pd.read_csv(\"train.csv\")\n",
    "y = X['Crime_Category']\n",
    "X = X.drop('Crime_Category', axis=1)\n",
    "\n",
    "# Remove column with 80% null values\n",
    "X.drop('Cross_Street', axis=1, inplace=True)\n",
    "\n",
    "# Handle missing data\n",
    "X['Victim_Sex'] = X['Victim_Sex'].replace(['H', 'X'], 'Unknown')\n",
    "X['Victim_Descent'] = X['Victim_Descent'].fillna('Unknown')\n",
    "X['Weapon_Description'] = X['Weapon_Description'].fillna('No Weapon')\n",
    "X['Weapon_Used_Code'] = X['Weapon_Used_Code'].fillna(0)  # Weapon_Used_Code is in the range [1,3990], 0 is for missing code\n",
    "X['Modus_Operandi'] = X['Modus_Operandi'].fillna('Unknown')\n",
    "\n",
    "# Date processing\n",
    "X['Date_Reported'] = pd.to_datetime(X['Date_Reported'], format='%m/%d/%Y %I:%M:%S %p', errors='coerce')\n",
    "X['Date_Occurred'] = pd.to_datetime(X['Date_Occurred'], format='%m/%d/%Y %I:%M:%S %p', errors='coerce')\n",
    "X['Year_Reported'] = X.Date_Reported.dt.year\n",
    "X['Year_Occurred'] = X.Date_Occurred.dt.year\n",
    "X['Month_Reported'] = X.Date_Reported.dt.month\n",
    "X['Month_Occurred'] = X.Date_Occurred.dt.month\n",
    "X['Day_Reported'] = X.Date_Reported.dt.day\n",
    "X['Day_Occurred'] = X.Date_Occurred.dt.day\n",
    "X.drop(['Date_Reported', 'Date_Occurred'], axis=1, inplace=True)\n",
    "\n",
    "numerical_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_columns = [col for col in categorical_columns if col != 'Modus_Operandi']\n",
    "\n",
    "numerical_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy='median'),\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "def label_encoding_column(df, column):\n",
    "    lab_encoder = LabelEncoder()\n",
    "    df[column] = lab_encoder.fit_transform(df[column])\n",
    "    return df\n",
    "\n",
    "for col in categorical_columns:\n",
    "  X = label_encoding_column(X, col)\n",
    "\n",
    "modus_operandi_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    CountVectorizer(preprocessor=lambda x:x[0])\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_pipeline, numerical_columns),\n",
    "    ('modus_operandi', modus_operandi_pipeline, ['Modus_Operandi'])\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full pipeline\n",
    "pipe = make_pipeline(preprocessor)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = pipe.transform(X_test)\n",
    "\n",
    "# label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from sparse to dense matrices\n",
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()\n",
    "\n",
    "# convert all the data in pytorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_encoded, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.long)\n",
    "\n",
    "# data loader for training and testing\n",
    "training_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "testing_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "training_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "testing_loader = DataLoader(testing_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the neural network\n",
    "class CrimeCategoryNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, output_dim=6):\n",
    "        super(CrimeCategoryNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout2 = nn.Dropout(p=0.3)\n",
    "\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # first layer\n",
    "        x = self.dropout1(self.relu(self.bn1(self.fc1(x))))\n",
    "        # second layer\n",
    "        x = self.dropout2(self.relu(self.bn2(self.fc2(x))))\n",
    "        # output layer\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# number of features in the training set\n",
    "input_dim = X_train.shape[1]\n",
    "model = CrimeCategoryNN(input_dim=input_dim)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5047\n",
      "Epoch 2, Loss: 0.2097\n",
      "Epoch 3, Loss: 0.1774\n",
      "Epoch 4, Loss: 0.1636\n",
      "Epoch 5, Loss: 0.1500\n",
      "Epoch 6, Loss: 0.1422\n",
      "Epoch 7, Loss: 0.1328\n",
      "Epoch 8, Loss: 0.1267\n",
      "Epoch 9, Loss: 0.1225\n",
      "Epoch 10, Loss: 0.1124\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in training_loader:\n",
    "        # zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        outputs = model(inputs)\n",
    "        # compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(training_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test images: 94.80%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testing_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f'Accuracy on the test images: {100 * correct / total:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
